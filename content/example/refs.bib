@article{10.1371/journal.pone.0231939,
    author = {Huppenkothen, Daniela AND McFee, Brian AND Norén, Laura},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Entrofy your cohort: A transparent method for diverse cohort selection},
    year = {2020},
    month = {07},
    volume = {15},
    url = {https://doi.org/10.1371/journal.pone.0231939},
    pages = {1-35},
    abstract = {Selecting a cohort from a set of candidates is a common task within and beyond academia. Admitting students, awarding grants, and choosing speakers for a conference are situations where human biases may affect the selection of any particular candidate, and, thereby the composition of the final cohort. In this paper, we propose a new algorithm, entrofy, designed to be part of a human-in-the-loop decision making strategy aimed at making cohort selection as just, transparent, and accountable as possible. We suggest embedding entrofy in a two-step selection procedure. During a merit review, the committee selects all applicants, submissions, or other entities that meet their merit-based criteria. This often yields a cohort larger than the admissible number. In the second stage, the target cohort can be chosen from this meritorious pool via a new algorithm and software tool called entrofy. entrofy optimizes differences across an assignable set of categories selected by the human committee. Criteria could include academic discipline, home country, experience with certain technologies, or other quantifiable characteristics. The entrofy algorithm then yields the approximation of pre-defined target proportions for each category by solving the tie-breaking problem with provable performance guarantees. We show how entrofy selects cohorts according to pre-determined characteristics in simulated sets of applications and demonstrate its use in a case study of Astro Hack Week. This two stage candidate and cohort selection process allows human judgment and debate to guide the assessment of candidates’ merit in step 1. Then the human committee defines relevant diversity criteria which will be used as computational parameters in entrofy. Once the parameters are defined, the set of candidates who meet the minimum threshold for merit are passed through the entrofy cohort selection procedure in step 2 which yields a cohort of a composition as close as possible to the computational parameters defined by the committee. This process has the benefit of separating the meritorious assessment of candidates from certain elements of their diversity and from some considerations around cohort composition. It also increases the transparency and auditability of the process, which enables, but does not guarantee, fairness. Splitting merit and diversity considerations into their own assessment stages makes it easier to explain why a given candidate was selected or rejected, though it does not eliminate the possibility of objectionable bias.},
    number = {7},
    doi = {10.1371/journal.pone.0231939}
}

@article{gregor2015draw,
  title={DRAW: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint arXiv:1502.04623},
  year={2015},
  url ={https://arxiv.org/pdf/1502.04623.pdf}
}
@article{mercier2011humans,
  title={Why do humans reason? Arguments for an argumentative theory},
  author={Mercier, Hugo and Sperber, Dan},
  journal={Behavioral and brain sciences},
  volume={34},
  number={02},
  pages={57--74},
  year={2011},
  publisher={Cambridge Univ Press},
  doi={10.1017/S0140525X10000968}
}
@article{dong2014image,
  title={Image super-resolution using deep convolutional networks},
  author={Dong, Chao and Loy, Chen Change and He, Kaiming and Tang, Xiaoou},
  journal={arXiv preprint arXiv:1501.00092},
  year={2014},
  url={https://arxiv.org/pdf/1501.00092.pdf}
}
@article{dumoulin2016adversarially,
  title={Adversarially Learned Inference},
  author={Dumoulin, Vincent and Belghazi, Ishmael and Poole, Ben and Lamb, Alex and Arjovsky, Martin and Mastropietro, Olivier and Courville, Aaron},
  journal={arXiv preprint arXiv:1606.00704},
  year={2016},
  url={https://arxiv.org/pdf/1606.00704.pdf}
}
@article{dumoulin2016guide,
  title={A guide to convolution arithmetic for deep learning},
  author={Dumoulin, Vincent and Visin, Francesco},
  journal={arXiv preprint arXiv:1603.07285},
  year={2016},
  url={https://arxiv.org/pdf/1603.07285.pdf}
}
@article{gauthier2014conditional,
  title={Conditional generative adversarial nets for convolutional face generation},
  author={Gauthier, Jon},
  journal={Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, Winter semester},
  volume={2014},
  year={2014},
  url={http://www.foldl.me/uploads/papers/tr-cgans.pdf}
}
@article{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  journal={arXiv preprint arXiv:1603.08155},
  year={2016},
  url={https://arxiv.org/pdf/1603.08155.pdf}
}
@article{mordvintsev2015inceptionism,
  title={Inceptionism: Going deeper into neural networks},
  author={Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike},
  journal={Google Research Blog},
  year={2015},
  url={https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html}
}
@misc{mordvintsev2016deepdreaming,
  title={DeepDreaming with TensorFlow},
  author={Mordvintsev, Alexander},
  year={2016},
  url={https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb},
}
@article{radford2015unsupervised,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal={arXiv preprint arXiv:1511.06434},
  year={2015},
  url={https://arxiv.org/pdf/1511.06434.pdf}
}
@inproceedings{salimans2016improved,
  title={Improved techniques for training gans},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2226--2234},
  year={2016},
  url={https://arxiv.org/pdf/1606.03498.pdf}
}
@article{shi2016deconvolution,
  title={Is the deconvolution layer the same as a convolutional layer?},
  author={Shi, Wenzhe and Caballero, Jose and Theis, Lucas and Huszar, Ferenc and Aitken, Andrew and Ledig, Christian and Wang, Zehan},
  journal={arXiv preprint arXiv:1609.07009},
  year={2016},
  url={https://arxiv.org/pdf/1609.07009.pdf}
}
